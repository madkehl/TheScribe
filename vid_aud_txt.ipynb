{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/extracting-speech-from-video-using-python-f0ec7e312d38\n",
    "#https://stackoverflow.com/questions/37999150/how-to-split-a-wav-file-into-multiple-wav-files\n",
    "import speech_recognition as sr \n",
    "import moviepy.editor as mp\n",
    "from pydub import AudioSegment\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitWavAudioMubin():\n",
    "    def __init__(self, folder, filename):\n",
    "        self.folder = folder\n",
    "        self.filename = filename\n",
    "        self.filepath = folder + '/' + filename\n",
    "        \n",
    "        self.audio = AudioSegment.from_wav(self.filepath)\n",
    "    \n",
    "    def get_duration(self):\n",
    "        return self.audio.duration_seconds\n",
    "    \n",
    "    def single_split(self, from_min, to_min, split_filename):\n",
    "        t1 = from_min * 60 * 1000\n",
    "        t2 = to_min * 60 * 1000\n",
    "        split_audio = self.audio[t1:t2]\n",
    "        split_audio.export(self.folder + '/' + split_filename, format=\"wav\")\n",
    "        \n",
    "    def multiple_split(self, min_per_split):\n",
    "        total_mins = math.ceil(self.get_duration() / 60)\n",
    "        for i in range(0, total_mins, min_per_split):\n",
    "            split_fn = str(i) + '_' + self.filename\n",
    "            self.single_split(i, i+min_per_split, split_fn)\n",
    "            print(str(i) + ' Done')\n",
    "            if i == total_mins - min_per_split:\n",
    "                print('All split successfully')\n",
    "                return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aud_to_text():\n",
    "    path = './trial/trial.wav'\n",
    "    r = sr.Recognizer()\n",
    "    audio = sr.AudioFile(path)\n",
    "    with audio as source:\n",
    "        audio_file = r.record(source)\n",
    "    result = r.recognize_google(audio_file, language='en-US', show_all=True)\n",
    "    if len(result) > 0:\n",
    "        print(result['alternative'][0])\n",
    "        return(result['alternative'][0]['transcript'])\n",
    "\n",
    "def aud_to_text_ls(count):\n",
    "    sub_files = range(count + 1)\n",
    "\n",
    "    full_transcript = \"\"\n",
    "    for i in sub_files:\n",
    "        path = './trial/' + str(i) + '_trial.wav'\n",
    "        result = aud_to_text()\n",
    "        full_transcript = full_transcript + result + ' '\n",
    "    #trying to throw the api off\n",
    "        time.sleep(10)\n",
    "        \n",
    "    return full_transcript\n",
    "\n",
    "def full_path_to_txt(movie_path, file_name, split = True):\n",
    "    \n",
    "    clip = mp.VideoFileClip(movie_path) \n",
    "    current_vid = file_name\n",
    "    os.mkdir('./trial')\n",
    "    clip.audio.write_audiofile(r'./trial/trial.wav')\n",
    "    \n",
    "    folder = './trial'\n",
    "    file = 'trial.wav'\n",
    "    \n",
    "    if split == True:\n",
    "        split_wav = SplitWavAudioMubin(folder, file)\n",
    "        count = split_wav.multiple_split(min_per_split=1)\n",
    "        full_transcript = aud_to_text_ls(count)\n",
    "    else:\n",
    "        full_transcript = aud_to_text()\n",
    "        \n",
    "    shutil.rmtree(folder)\n",
    "    text_file = open(current_vid, \"w\")\n",
    "    text_file.write(full_transcript)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data_submission1.mp4', <http.client.HTTPMessage at 0x7f9630ab7fd0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url_link = 'https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/1_Introduction.mp4'\n",
    "#url_link = 'https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/2_Getting_Started.mp4'\n",
    "#url_link = 'https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/3_Validate_Data.mp4'\n",
    "#url_link = 'https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/4_Custom_Scope.mp4'\n",
    "#url_link = \"https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/5_Correcting_Errors.mp4\"\n",
    "#url_link = \"https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/6_Asking-for_Help.mp4\"\n",
    "#url_link = \"https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/7_Asking_for_Help.mp4\"\n",
    "#url_link = \"https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/8_Build_Package.mp4\"\n",
    "#url_link = \"https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/9_Upload_Package.mp4\"\n",
    "#url_link = \"https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/10_Completing_the_Submission.mp4\"\n",
    "#url_link = \"https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/11_Resuming-a_Submission_in_Progress.mp4\"\n",
    "\n",
    "url_link = \"https://s3.amazonaws.com/data-archive.nimh.nih.gov/Documents/Tutorials/Training/Create_an_Account.mp4\"\n",
    "urllib.request.urlretrieve(url_link, 'data_submission1.mp4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_path = r'2351285129819900164.mp4'\n",
    "#movie_path = r'5433273397410606852.mp4'\n",
    "#movie_path = r'2366109844211546884.mp4'\n",
    "#movie_path = r'4047124581474259204.mp4'\n",
    "movie_path = r'data_submission1.mp4'\n",
    "current_vid = 'data_submission1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  24%|██▍       | 333/1368 [00:00<00:00, 3324.85it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ./trial/trial.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "{'transcript': 'the first step in the new distribution process will be to obtain user accounts in the appropriate access privileges for yourself and any additional Personnel will be assisting', 'confidence': 0.88818198}\n"
     ]
    }
   ],
   "source": [
    "full_path_to_txt(movie_path, current_vid, split = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
